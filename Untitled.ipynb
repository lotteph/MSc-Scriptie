{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f508c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic python packages\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "# General machine learning packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Packages related to images\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "# Packages for neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Embedding\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f09a838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU works\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aab2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths to different folders/files\n",
    "image_dir = \"../Data/Rijksmuseum/jpg2\"\n",
    "train_dir = \"../Data/Rijksmuseum/train_set\"\n",
    "resized_train_dir = \"..Data/Rijksmuseum/resized_jpg2\"\n",
    "test_image_dir = \"../Data/Rijksmuseum/test_set\"\n",
    "labels_file = \"../Data/Rijksmuseum/xml_files.csv\"\n",
    "training_path = \"../Data/Rijksmuseum/training_data/\"\n",
    "validation_path = \"../Data/Rijksmuseum/validation_data/\"\n",
    "\n",
    "img_size = (200, 200) #Size of the input of the neural networks\n",
    "IMG_SHAPE = img_size + (3,)\n",
    "batch_size = 32\n",
    "n_labels = 6,622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27e8aad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Creator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SK-A-4878</td>\n",
       "      <td>Everdingen, Caesar Boëtius van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SK-A-4877</td>\n",
       "      <td>Maris, Matthijs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SK-A-4881</td>\n",
       "      <td>Maes, Nicolaes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RP-P-1992-35</td>\n",
       "      <td>Coornhert, Dirck Volckertsz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RP-P-1992-36</td>\n",
       "      <td>Coornhert, Dirck Volckertsz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112034</th>\n",
       "      <td>AK-RBK-14763-A-2</td>\n",
       "      <td>anoniem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112035</th>\n",
       "      <td>RP-P-OB-86.512</td>\n",
       "      <td>Bos, Maarten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112036</th>\n",
       "      <td>NG-NM-7753</td>\n",
       "      <td>anoniem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112037</th>\n",
       "      <td>NG-NM-8358</td>\n",
       "      <td>Coenraads, Jacobus (Senior)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112038</th>\n",
       "      <td>NG-KOG-2192</td>\n",
       "      <td>George</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112039 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Identifier                          Creator\n",
       "0              SK-A-4878   Everdingen, Caesar Boëtius van\n",
       "1              SK-A-4877                  Maris, Matthijs\n",
       "2              SK-A-4881                   Maes, Nicolaes\n",
       "3           RP-P-1992-35      Coornhert, Dirck Volckertsz\n",
       "4           RP-P-1992-36      Coornhert, Dirck Volckertsz\n",
       "...                  ...                              ...\n",
       "112034  AK-RBK-14763-A-2                          anoniem\n",
       "112035    RP-P-OB-86.512                     Bos, Maarten\n",
       "112036        NG-NM-7753                          anoniem\n",
       "112037        NG-NM-8358      Coenraads, Jacobus (Senior)\n",
       "112038       NG-KOG-2192                           George\n",
       "\n",
       "[112039 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(labels_file)\n",
    "# labels[['Identifier', 'Creator']]\n",
    "\n",
    "labels = labels[['Identifier', 'Creator']]\n",
    "# subs = subs.set_index('Identifier')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55ec04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d8d7cd7",
   "metadata": {},
   "source": [
    "# Image size\n",
    "Most machine learning requires that the input is always of the same size. Because our images are not always of the same size. We have to resize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db1d8e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_names, img_dir, new_img_dir):\n",
    "    #Deprecated, replaced by the flow from directory\n",
    "    for img in img_names:\n",
    "        Image.open(img_dir + \"/\" + img + \".jpg\").resize(img_size).save(new_img_dir + \"/\" + img + \".jpg\")\n",
    "\n",
    "resize_images(labels[\"Identifier\"], image_dir, resized_train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b9734",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2442b753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RP-P-BI-250', 'RP-P-BI-6678', 'RP-P-1880-A-4126', ...,\n",
       "       'RP-P-1944-663', 'SK-C-221', 'RP-P-1918-2049'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(labels[\"Identifier\"].to_numpy(), labels[\"Creator\"].to_numpy(), test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112d792f",
   "metadata": {},
   "source": [
    "# Reformat data for learning\n",
    "To be able to load the data with a generator. We must split the training and validation data and place them into a folder based on their label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_folders(image_path, image_names, image_labels, destination_path):\n",
    "    \"\"\"\n",
    "    Splits a single folder with images into multiple folders where images are placed based on their labels.\n",
    "\n",
    "    :image_path: path to the folder with the images\n",
    "    :image_names: A numpy array with the names of all images\n",
    "    :image_labels: A numpy array with the labels of all images\n",
    "    :destination_path: Path of the folder where the images are placed into\n",
    "    :return: Nothing\n",
    "    \"\"\" \n",
    "    for i in range(len(image_names)):\n",
    "        # Check if the directory exists. Else, make one\n",
    "        isExist = os.path.exists(destination_path + str(image_labels[i]))\n",
    "        if not isExist:\n",
    "            os.makedirs(destination_path + str(image_labels[i]))\n",
    "            \n",
    "        # Copy the image\n",
    "        img = Image.open(image_path + \"/\" + image_names[i] + \".jpg\")\n",
    "        img.save(destination_path + \"/\" + str(image_labels[i]) + \"/\" + image_names[i] + \".jpg\")\n",
    "        \n",
    "\n",
    "# generate_label_folders(image_dir, X_train, y_train, training_path)\n",
    "# generate_label_folders(image_dir, X_test, y_test, test_image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c2b90",
   "metadata": {},
   "source": [
    "# Image Loading\n",
    "Because the dataset is so large, we cant just load it into our memory. Instead we generate batches of images. These images are then altered a little bit to create higher variance between images and artificially increase the size of our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19870b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=normalize,\n",
    "        shear_range=2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range = 2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=normalize)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        training_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_image_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, steps_per_epoch=150, epochs=3, validation_steps=20, workers=7, checkpoint_loc=\"\"):\n",
    "    \"\"\"\n",
    "    Trains a given model\n",
    "\n",
    "    :steps_per_epoch: Amount of batches uploaded per epoch. Cant be higher than +- 200\n",
    "    :epochs: Amount of times the model trains on the data\n",
    "    :validation_steps: Amount of batches used for validation. Cant be higher than +- 50\n",
    "    :workers: Amount of processes used to load the data\n",
    "    :checkpoint_loc: Place for the model checkpoints to be saved\n",
    "    :return: The trained model and some training data\n",
    "    \"\"\" \n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_loc,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "    begin_time = datetime.datetime.now()\n",
    "    history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs, validation_data=validation_generator, validation_steps=validation_steps, workers=workers, callbacks=[cp_callback])\n",
    "    print(datetime.datetime.now() - begin_time)\n",
    "    return (model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae11ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    #Plots the training data.\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e00d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(n_labels):\n",
    "    base_model = tf.keras.applications.EfficientNetV2L(input_shape=IMG_SHAPE,\n",
    "                          include_top=False,\n",
    "                          weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "\n",
    "\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    prediction_layer = tf.keras.layers.Dense(n_labels)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "      base_model,\n",
    "      global_average_layer,\n",
    "      prediction_layer\n",
    "    ])\n",
    "\n",
    "    base_learning_rate = 0.0001\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "InceptionResNetV2model = make_model(n_labels)\n",
    "# InceptionResNetV2model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34273795",
   "metadata": {},
   "outputs": [],
   "source": [
    "InceptionResNetV2model, history_InceptionResNetV2 = train_model(InceptionResNetV2model, steps_per_epoch=100, epochs=5, validation_steps=50, checkpoint_loc=\"../Model_weights/InceptionResNetV2/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43452f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_InceptionResNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352fe6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "InceptionResNetV2model.save(\"models/_InceptionResNetV2model\")\n",
    "\n",
    "# Load model\n",
    "# InceptionResNetV2model = tf.keras.models.load_model('./models/_InceptionResNetV2model')\n",
    "# Epochs trained: 5, 5, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05e0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9630a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ac731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
